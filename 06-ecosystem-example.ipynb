{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center><span style=\"color:green\">Ecosystem example</span></center></h2>\n",
    "\n",
    "### **\"Thinking outside the box\"**\n",
    "\n",
    "Other groups and projects are working on other domain-specific areas towards the common goal of a modern, Pythonic and friendly analysis ecosystem for HEP. Let's play a bit with the `phasespace` and `zfit` packages from the **zfit project**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Acknowledgements:**\n",
    "\n",
    "This tutorial is largely based on code kindly provided by Jonas Eschle (University of Zurich).\n",
    "It showcases the generation and fit of samples of $ B \\to K^* \\mu^+ \\mu^-$ events,\n",
    "including a simultaneous, and the subsequent determination of the signal significance.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from particle.particle import literals as lp\n",
    "from phasespace import GenParticle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 11  # \"good\" seed: 11\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# TODO: @Eduardo, maybe change this to demonstrate the particle package? Alternative ways\n",
    "KSTARZ_MASS = lp.Kst_892_0.mass\n",
    "KSTARZ_WIDTH = lp.Kst_892_0.width\n",
    "B0_MASS = lp.B_0.mass\n",
    "PION_MASS = lp.pi_minus.mass\n",
    "KAON_MASS = lp.K_plus.mass\n",
    "MU_MASS = lp.mu_minus.mass\n",
    "JPSI_MASS = lp.Jpsi_1S.mass\n",
    "\n",
    "# overall parameters to change\n",
    "n_sig_rare = 120\n",
    "n_sig_reso = 4000\n",
    "n_bkg_rare = 5000\n",
    "n_bkg_reso = 3000\n",
    "\n",
    "rare_smearing = 7  # detector smearing of the particles 4-momenta (sigma of a gaussian)\n",
    "reso_smearing = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************\n",
    "# PHASESPACE GENERATION OF RARE SIGNAL\n",
    "# *************************************************\n",
    "\n",
    "# kstar is resonant, we define here the sampling of the mass\n",
    "# therefore we can use zfit PDF or TensorFlow Probability (or anything if wrappet with `tf.py_function`\n",
    "def kstar_mass(min_mass, max_mass, n_events):\n",
    "    min_mass = tf.cast(min_mass, tf.float64)\n",
    "    max_mass = tf.cast(max_mass, tf.float64)\n",
    "    kstar_width_cast = tf.cast(KSTARZ_WIDTH, tf.float64)\n",
    "    kstar_mass_cast = tf.cast(KSTARZ_MASS, dtype=tf.float64)\n",
    "\n",
    "    kstar_mass = tf.broadcast_to(kstar_mass_cast, shape=(n_events,))\n",
    "    if KSTARZ_WIDTH > 0:\n",
    "        kstar_mass = tfp.distributions.TruncatedNormal(loc=kstar_mass,\n",
    "                                                       scale=kstar_width_cast,\n",
    "                                                       low=min_mass,\n",
    "                                                       high=max_mass).sample()\n",
    "    return kstar_mass\n",
    "\n",
    "\n",
    "kstar = GenParticle('K*0', mass=kstar_mass).set_children(GenParticle('K+', mass=KAON_MASS),\n",
    "                                                         GenParticle('pi-', mass=PION_MASS))\n",
    "bz = GenParticle('B0', B0_MASS).set_children(kstar,\n",
    "                                             GenParticle('mu+', mass=MU_MASS),\n",
    "                                             GenParticle('mu-', mass=MU_MASS)\n",
    "                                             )\n",
    "weights, particles = bz.generate(n_sig_rare)\n",
    "weights = weights / np.average(weights)\n",
    "\n",
    "\n",
    "# to make it look real (similar to what RapidSim does), we smear the particles\n",
    "def smear_momenta(four_momenta, smearing=10):\n",
    "    # the four_momenta are \"eager_tensors\", wrapped numpy arrays. We could convert them with `np.array(four_momenta)`\n",
    "    return np.random.normal(loc=four_momenta, scale=smearing)\n",
    "\n",
    "\n",
    "def invariant_mass(four_momenta):\n",
    "    momenta_squared = four_momenta ** 2\n",
    "    return np.sqrt(momenta_squared[:, 3] - np.sum((momenta_squared[:, :3]), axis=-1))\n",
    "\n",
    "\n",
    "smeared_momenta = {}\n",
    "daugther_particles = ['K+', 'pi-', 'mu+', 'mu-']\n",
    "for particle in daugther_particles:\n",
    "    smeared_momenta[particle] = smear_momenta(particles[particle], smearing=rare_smearing)\n",
    "\n",
    "smeared_momenta['K*0'] = smeared_momenta['K+'] + smeared_momenta['pi-']\n",
    "smeared_momenta['Jpsi'] = smeared_momenta['mu+'] + smeared_momenta['mu-']\n",
    "smeared_momenta['B0'] = smeared_momenta['K*0'] + smeared_momenta['Jpsi']\n",
    "\n",
    "b_mass_rare = invariant_mass(smeared_momenta['B0'])\n",
    "q2 = invariant_mass(smeared_momenta['Jpsi'])\n",
    "\n",
    "# plot the b mass with the weights. It is basically the same as without weights.\n",
    "plt.figure()\n",
    "plt.title(\"B mass generated non resonant\")\n",
    "plt.hist(b_mass_rare, weights=weights, alpha=0.5, bins=40, label=\"with weights\")\n",
    "plt.hist(b_mass_rare, bins=40, alpha=0.5, label=\"no weights\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"q2 generated non resonant\")\n",
    "plt.hist(q2, weights=weights, alpha=0.5, bins=40, label=\"with weights\")\n",
    "plt.hist(q2, bins=40, alpha=0.5, label=\"no weights\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************\n",
    "# START FIT\n",
    "# *************************************************\n",
    "#\n",
    "# The fit goes in three steps:\n",
    "# - a fit with the exponential to the right side to have a good\n",
    "#   starting value.\n",
    "# - a model composed of an exponential for the combinatorial bkg and a double Crystalball for\n",
    "#   the signal is built and fitted to the \"rare\" mode\n",
    "# - the same model with a few shared parameters is built for the resonant mode to improve the shape\n",
    "#   of the DoubleCB, as moslty the tails are tricky. They seem to be independent of q2, so we\n",
    "#   can share them\n",
    "\n",
    "# --------------------------------------------------\n",
    "# RIGHT SIDE BAND FIT\n",
    "# --------------------------------------------------\n",
    "\n",
    "import zfit\n",
    "\n",
    "# TODO @Eduardo: maybe adjust the range?\n",
    "upper_limit = 5600\n",
    "obs = zfit.Space('Bmass', (5000, upper_limit))  # for whole range\n",
    "obs_bkg = zfit.Space('Bmass', (5400, upper_limit))  # to pre-fit the exponential\n",
    "\n",
    "# Parameters are specified:  (name (unique), initial, lower, upper) whereas lower, upper are optional\n",
    "lambda_rare = zfit.Parameter('lambda_rare', -0.002, -0.01, -0.0001, step_size=0.001)  # floating, also without limits\n",
    "comb_bkg_rare = zfit.pdf.Exponential(lambda_rare, obs=obs)\n",
    "\n",
    "# create some bkg data\n",
    "comb_bkg_rare_sample = comb_bkg_rare.sample(n=n_bkg_rare)  # sampled within the limits of `obs`\n",
    "\n",
    "# to improve our fit, we can prefit the rightside\n",
    "right_tale_data_rare = zfit.Data.from_numpy(obs=obs_bkg, array=comb_bkg_rare_sample.value())\n",
    "\n",
    "# set the value of lambda to smth different than we sampled from (for the fit afterwards)\n",
    "lambda_rare.set_value(-0.003)\n",
    "\n",
    "# here we temporarily set the normalization range to the right side only\n",
    "with comb_bkg_rare.set_norm_range(obs_bkg):\n",
    "    right_tale_loss = zfit.loss.UnbinnedNLL(comb_bkg_rare, right_tale_data_rare)\n",
    "    minimizer = zfit.minimize.Minuit(verbosity=7)\n",
    "    minimizer._use_tfgrad = False\n",
    "    result_right_tale = minimizer.minimize(right_tale_loss)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# RARE MODE FIT\n",
    "# --------------------------------------------------\n",
    "\n",
    "# now create the data for the rare fit\n",
    "rare_data_np = np.concatenate([b_mass_rare, comb_bkg_rare_sample[:, 0]], axis=0)\n",
    "rare_weights_np = np.concatenate([weights, np.ones_like(comb_bkg_rare_sample[:, 0])], axis=0)\n",
    "# TODO @Eduardo, we could do some data preprocessing here (e.g. apply a cut to q2, which we actually\n",
    "# need to have \"no Jpsi\" in there. This can be done with pandas and then loaded into zfit\n",
    "\n",
    "rare_data = zfit.Data.from_numpy(obs=obs, array=rare_data_np, weights=rare_weights_np)\n",
    "# we can also load data from ROOT\n",
    "# right_tale_data_rare = zfit.Data.from_root(...)\n",
    "\n",
    "# ...or to/from a pandas DataFrame. Either convert the `zfit.Data` to a pandas DF\n",
    "# right_tale_data_rare_df = right_tale_data_rare.to_pandas()\n",
    "# .... or create it from scratch\n",
    "# right_tale_data_rare_df = pd.DataFrame(data=rare_data_np, columns=obs_bkg.obs)\n",
    "# Then we can directly load it\n",
    "# right_tale_data_rare = zfit.Data.from_pandas(df=right_tale_data_rare_df, obs=obs_bkg)\n",
    "\n",
    "# TODO @eduardo: maybe remove plot, just for data visualization example?\n",
    "plt.figure()\n",
    "plt.title(\"B mass and bkg\")\n",
    "plt.hist(rare_data_np, weights=rare_weights_np, bins=40)\n",
    "\n",
    "# create the model to fit\n",
    "\n",
    "# set the normalization range of the exponential to the whole range\n",
    "comb_bkg_rare.set_norm_range(obs)\n",
    "\n",
    "# parameters for the model\n",
    "mu = zfit.Parameter('mu', 5270, 5200, 5350)\n",
    "sigma = zfit.Parameter('sigma', 22, 0, 100)\n",
    "\n",
    "# we could also use a smple model here\n",
    "# signal_rare = zfit.pdf.Gauss(mu=mu, sigma=sigma, obs=obs)\n",
    "\n",
    "# We will use a double crystall ball\n",
    "alphal_rare = zfit.Parameter('alpha left rare', -0.3, -5, 0)\n",
    "nl_rare = zfit.Parameter('n left rare', 0.3, 0, 10)\n",
    "alphar_rare = zfit.Parameter('alpha right rare', 1, 0, 5)\n",
    "nr_rare = zfit.Parameter('n right rare', 2.8, 0, 10)\n",
    "frac_dcb_rare = zfit.Parameter('frac dcb', 0.3, 0.1, 0.9)\n",
    "\n",
    "left_cb_rare = zfit.pdf.CrystalBall(obs=obs,\n",
    "                                    mu=mu, sigma=sigma,\n",
    "                                    alpha=alphal_rare, n=nl_rare,\n",
    "                                    )\n",
    "right_cb_rare = zfit.pdf.CrystalBall(obs=obs,\n",
    "                                     mu=mu, sigma=sigma,\n",
    "                                     alpha=alphar_rare, n=nr_rare,\n",
    "                                     )\n",
    "signal_rare = zfit.pdf.SumPDF([left_cb_rare, right_cb_rare], fracs=frac_dcb_rare)\n",
    "\n",
    "# now create the yields and the extended pdfs\n",
    "rare_sig_yield = zfit.Parameter('rare_sig_yield', n_sig_rare + 30,\n",
    "                                step_size=3)  # step size: default is small, use appropriate\n",
    "rare_bkg_yield = zfit.Parameter('rare_bkg_yield', n_bkg_rare - 40, step_size=1)\n",
    "extended_sig_rare = signal_rare.create_extended(rare_sig_yield)\n",
    "extended_bkg_rare = comb_bkg_rare.create_extended(rare_bkg_yield)\n",
    "model_rare = zfit.pdf.SumPDF([extended_bkg_rare, extended_sig_rare])\n",
    "\n",
    "\n",
    "# in order to plot our model (before the fit), we create a helper here\n",
    "def plot_pdf_data(data, model, title, n_bins=40):\n",
    "    linewidth = 2.5\n",
    "    space = data.data_range\n",
    "    plot_scaling = data.nevents / n_bins * space.area()\n",
    "    lower, upper = space.limit1d\n",
    "    x = np.linspace(lower, upper, 1000)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "\n",
    "    # plot the data\n",
    "    data_np = data[:, 0]\n",
    "    plt.hist(data_np,\n",
    "             # color=color,\n",
    "             bins=n_bins, histtype=\"stepfilled\", alpha=0.1)\n",
    "    plt.hist(data_np,\n",
    "             # color=color,\n",
    "             bins=n_bins, histtype=\"step\")\n",
    "    # plot the pdfs\n",
    "    y = model.pdf(x).numpy()\n",
    "    y_sig = (model.pdfs[0].pdf(x) * model.fracs[0]).numpy()  # notice the frac!\n",
    "    y_bkg = (model.pdfs[1].pdf(x) * model.fracs[1]).numpy()  # notice the frac!\n",
    "\n",
    "    plt.plot(x, y * plot_scaling, label=\"Sum - Model\", linewidth=linewidth * 2)\n",
    "    plt.plot(x, y_sig * plot_scaling, '--', label=f\"{model.pdfs[0].name} - Signal\", linewidth=linewidth)\n",
    "    plt.plot(x, y_bkg * plot_scaling, '--', label=f\"{model.pdfs[1].name} - Background\", linewidth=linewidth)\n",
    "    plt.xlabel(space.obs[0])\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "plot_pdf_data(data=rare_data, model=model_rare, title='before fitting: $B^0 -> K^{*} (-> K^+ \\pi^-) \\mu^+ \\mu^-$')\n",
    "plt.show()\n",
    "\n",
    "# create a loss: the minimum of it well-defines the solution to our problem\n",
    "ext_rare_nll = zfit.loss.ExtendedUnbinnedNLL(model_rare, rare_data)\n",
    "\n",
    "result_rare = minimizer.minimize(ext_rare_nll)\n",
    "# we could also specify the params explicitly; now all floating are used\n",
    "plot_pdf_data(data=rare_data, model=model_rare, title='after rare fitting: $B^0 -> K^{*} (-> K^+ \\pi^-) \\mu^+ \\mu^-$')\n",
    "plt.show()\n",
    "# all the parameters are set to the minimum of the fit. To store the fit information, we can\n",
    "# use the FitResult that is returned. It contains e.g. information about the parameter\n",
    "pprint(result_rare.params)\n",
    "\n",
    "# ...and more:\n",
    "print(f\"The fit converged: {result_rare.converged}, the minimum is {result_rare.fmin}\")\n",
    "\n",
    "# the following are error estimations. They add their result into the `params` attribute.\n",
    "# Unfortunately, hesse is currently not yet supported with weights.\n",
    "# result_rare.hesse()  # error calculation using the inverse hessian approximation\n",
    "# result_rare.error()  # error calculation using minos, this takes all parameters (expensive)\n",
    "result_rare.error([rare_sig_yield, mu])  # just for specific parameters\n",
    "pprint(result_rare.params)\n",
    "\n",
    "# the params can be accesssed using the parameter objects\n",
    "mu_rare_fit = result_rare.params[mu]\n",
    "# they contain information about the result such as value etc\n",
    "print(f\"Mu value of rare fit: {mu_rare_fit['value']} \"\n",
    "      f\"+ {mu_rare_fit['minuit_minos']['upper']} \"\n",
    "      f\"- {mu_rare_fit['minuit_minos']['upper']}\"\n",
    "      # f\" (symmetric Hesse error: {mu_rare_fit['minuit_hesse']['error']})\"\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************\n",
    "# PHASESPACE GENERATION OF RESONANT SIGNAL\n",
    "# *************************************************\n",
    "# Since the previous fit, e.g. the tail, was not so great due to the lack of statistics, we can\n",
    "# also fit the resonant mode and share certain parameters\n",
    "\n",
    "# create the resonant decay\n",
    "bz = GenParticle('B0', B0_MASS).set_children(kstar,\n",
    "                                             GenParticle('Jpsi', mass=JPSI_MASS).set_children(\n",
    "                                                 GenParticle('mu+', mass=MU_MASS),\n",
    "                                                 GenParticle('mu-', mass=MU_MASS)\n",
    "                                             ))\n",
    "\n",
    "weights_reso, particles_reso = bz.generate(n_sig_reso)\n",
    "weights_reso /= np.average(weights_reso)\n",
    "\n",
    "smeared_momenta_reso = {}\n",
    "daugther_particles_reso = ['K+', 'pi-', 'mu+', 'mu-']\n",
    "for particle in daugther_particles_reso:\n",
    "    smeared_momenta_reso[particle] = smear_momenta(particles_reso[particle], smearing=reso_smearing)\n",
    "\n",
    "smeared_momenta_reso['K*0'] = smeared_momenta_reso['K+'] + smeared_momenta_reso['pi-']\n",
    "smeared_momenta_reso['Jpsi'] = smeared_momenta_reso['mu+'] + smeared_momenta_reso['mu-']\n",
    "smeared_momenta_reso['B0'] = smeared_momenta_reso['K*0'] + smeared_momenta_reso['Jpsi']\n",
    "\n",
    "b_mass_reso = invariant_mass(smeared_momenta_reso['B0'])\n",
    "q2_reso = invariant_mass(smeared_momenta_reso['Jpsi'])\n",
    "\n",
    "# plot the q2\n",
    "plt.figure()\n",
    "plt.title(\"q2 generated resonant\")\n",
    "plt.hist(q2_reso, weights=weights_reso, alpha=0.5, bins=40, label=\"with weights\")\n",
    "plt.hist(q2_reso, bins=40, alpha=0.5, label=\"no weights\")\n",
    "plt.legend()\n",
    "\n",
    "# ------------------------------------------------\n",
    "# COMBINATORIAL BACKGROUND RESO\n",
    "# ------------------------------------------------\n",
    "\n",
    "lambda_reso = zfit.Parameter('lambda_reso', -0.002, -0.01, 0.0001)  # floating, also without limits\n",
    "comb_bkg_reso_pdf = zfit.pdf.Exponential(lambda_reso, obs=obs)\n",
    "\n",
    "# create some more bkg data\n",
    "comb_bkg_reso_sample = comb_bkg_reso_pdf.sample(n=n_bkg_reso)  # sampled within the limits of `obs`\n",
    "\n",
    "# set the value of lambda to smth different then we sampled from (for the fit afterwards)\n",
    "lambda_reso.set_value(-0.01)\n",
    "\n",
    "reso_data_np = np.concatenate([b_mass_reso, comb_bkg_reso_sample[:, 0]], axis=0)\n",
    "reso_weights_np = np.concatenate([weights_reso, np.ones_like(comb_bkg_reso_sample[:, 0])], axis=0)\n",
    "\n",
    "# TODO @eduardo: maybe remove plot, just for data visualization example?\n",
    "plt.figure()\n",
    "plt.title(\"resonant data\")\n",
    "plt.hist(reso_data_np, weights=reso_weights_np, bins=40)\n",
    "\n",
    "reso_data = zfit.Data.from_numpy(obs=obs, array=reso_data_np)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# RESONANT MODEL\n",
    "# ------------------------------------------------\n",
    "\n",
    "# create the model to fit\n",
    "\n",
    "# we can share parameters directly or create composed parameters. Here we have a\n",
    "# parameter that scales the sigma from the rare fit\n",
    "\n",
    "sigma_scaling = zfit.Parameter('sigma_scaling', 0.9, 0.1, 10)\n",
    "\n",
    "\n",
    "def sigma_scaled_fn():\n",
    "    return sigma * sigma_scaling  # this can be an arbitrary function\n",
    "\n",
    "\n",
    "sigma_scaled = zfit.ComposedParameter('sigma scaled', sigma_scaled_fn,\n",
    "                                      dependents=sigma  # the objects used inside the func\n",
    "                                      )\n",
    "\n",
    "# we could also make the free parameters, not shared\n",
    "# alphal_reso = zfit.Parameter('alpha left reso', -0.7, -5, 0)\n",
    "# nl_reso = zfit.Parameter('n left reso', 0.4, 0, 10)\n",
    "# alphar_reso = zfit.Parameter('alpha right reso', 1, 0, 5)\n",
    "# nr_reso = zfit.Parameter('n right reso', 1.8, 0, 10)\n",
    "\n",
    "alphal_reso = alphal_rare\n",
    "nl_reso = nl_rare\n",
    "alphar_reso = alphal_rare\n",
    "nr_reso = nr_rare\n",
    "\n",
    "# frac_dcb_reso = zfit.Parameter('frac dcb_reso', 0.5, 0.01, 0.99)\n",
    "frac_dcb_reso = frac_dcb_rare\n",
    "left_cb_reso = zfit.pdf.CrystalBall(obs=obs,\n",
    "                                    mu=mu, sigma=sigma_scaled,\n",
    "                                    alpha=alphal_reso, n=nl_reso,\n",
    "                                    )\n",
    "right_cb_reso = zfit.pdf.CrystalBall(obs=obs,\n",
    "                                     mu=mu, sigma=sigma_scaled,\n",
    "                                     alpha=alphar_reso, n=nr_reso,\n",
    "                                     )\n",
    "signal_reso = zfit.pdf.SumPDF([left_cb_reso, right_cb_reso], fracs=frac_dcb_reso)\n",
    "\n",
    "# or we can use a simpler shape\n",
    "# signal_reso = zfit.pdf.Gauss(mu=mu,  # using the same mu as above means it's shared\n",
    "#                              sigma=sigma_scaled, obs=obs)\n",
    "\n",
    "reso_sig_yield = zfit.Parameter('reso_sig_yield', n_sig_reso - 100, 0, n_sig_reso * 3,\n",
    "                                step_size=1)  # step size: default is small, use appropriate\n",
    "reso_bkg_yield = zfit.Parameter('reso_bkg_yield', n_bkg_reso + 70, 0, n_bkg_reso * 3, step_size=1)\n",
    "extended_sig_reso = signal_reso.create_extended(reso_sig_yield)\n",
    "extended_bkg_reso = comb_bkg_reso_pdf.create_extended(reso_bkg_yield)\n",
    "model_reso = zfit.pdf.SumPDF([extended_bkg_reso, extended_sig_reso])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# SIMULTANEOUS LOSS\n",
    "# ------------------------------------------------\n",
    "\n",
    "# we could also add a constraint to the loss\n",
    "# constraint = zfit.constraint.GaussianConstraint(mu, observation=5279, uncertainty=50)\n",
    "# ext_reso_nll = zfit.loss.ExtendedUnbinnedNLL(model_reso, reso_data, constraints=constraint)\n",
    "ext_reso_nll = zfit.loss.ExtendedUnbinnedNLL(model_reso, reso_data)\n",
    "\n",
    "# to create a simultaneous loss, we simply add them\n",
    "simultaneous_loss = ext_reso_nll + ext_rare_nll\n",
    "\n",
    "result_simult = minimizer.minimize(simultaneous_loss)\n",
    "\n",
    "plot_pdf_data(data=rare_data, model=model_rare, title='$B^0 -> K^{*} (-> K^+ \\pi^-) \\mu^+ \\mu^-$')\n",
    "plot_pdf_data(data=reso_data, model=model_reso, title='$B^0 -> K^{*} (-> K^+ \\pi^-) J/\\psi (-> \\mu^+ \\mu^-)$')\n",
    "plt.show()\n",
    "\n",
    "# Hesse is not yet supported with weights\n",
    "# result_simult.hesse()  # error calculation using hesse\n",
    "errors = result_simult.error([mu, rare_sig_yield, reso_sig_yield])  # error calculation using minos, just for a few\n",
    "# parameters as it is quite expensive\n",
    "pprint(errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# DETERMINING THE SIGNIFICANCE\n",
    "# ------------------------------------------------\n",
    "\n",
    "# using hepstats for the limits\n",
    "from hepstats.hypotests import Discovery\n",
    "from hepstats.hypotests.calculators import AsymptoticCalculator\n",
    "from hepstats.hypotests.parameters import POI\n",
    "\n",
    "calculator = AsymptoticCalculator(simultaneous_loss, minimizer)\n",
    "poinull = POI(rare_sig_yield, 0)\n",
    "discovery_test = Discovery(calculator, poinull)\n",
    "pnull, significance = discovery_test.result()\n",
    "print(f'pnull: {pnull} with significance {significance}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
